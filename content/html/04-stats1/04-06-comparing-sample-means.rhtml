<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Karma">
    <link rel="stylesheet" href="../highlight/styles/default.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="../css/stylesheet.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>
    <script src="../highlight/highlight.js"></script>
    <script src="../functions.js"></script>
    <script>hljs.highlightAll();</script>
    <script> 
    $(function(){
    $("#header").load("../common/head.html"); 
    });
    </script> 
</head>
<body>
  <!--Add in the header-->
  <div id="header"></div>
<main style = margin-top:100px>
  <nav class="section-nav">
      <ol>
        <li><a href="#ttest">Two-Sided T-tests</a>
          <ol>
            <li><a href="#ttest--ass">Assumptions</a>
            <ol>
              <li><a href="#ttest--ass--norm">Normality</a></li>
              <li><a href="#ttest--ass--homo">Homoskedasticity</a></li>
            </ol>
            </li>
            <li><a href="#ttest--test">The test</a></li>
          </ol>
        </li>
        <li><a href="#oneside">One-Sided T-tests</a></li>
        <li><a href="#nonnormal">Non-normality</a></li>
        <li><a href="#nonpara">Nonparametric Alternatives</a>
          <ol>
            <li><a href="#nonpara--ass">Assumptions</a>
            <ol>
              <li><a href="#nonpara--ass--cont">Continuity</a></li>
              <li><a href="#nonpara--ass--skew">Skew</a></li>
            </ol>
            </li>
            <li><a href="#nonpara--test">The test</a></li>
          </ol>
        </li>
      </ol>
    </nav>
  <div>
    <section id="work">
      <h2>Comparisons Between Sample Means</h2>
      <p>
        It's often the case that we may sample independently from a population, and develop some hypothesis that may indicate that the means for the independent samples are in fact different from one another. Taking the example we noted in the <a href="./04-04-hypothesis-testing.html">hypothesis testing</a> section, perhaps we care about the size of fiddler crabs, and if the crabs are from multiple sites, we could say that, between two sites of interest, we might believe there to be a size difference. Well, let's perform a statistical test to see if this is true.
      </p>
      <p>
        It is generally best in statistics, especially when starting our our own individual journeys as statisticians, to choose the simplest test that A) will answer our question, and B) we can satisfy the assumptions of. 
      </p>
      <p>
        When comparing two sample means, the standard test to perform here is the <strong>unpaired two-sample t-test</strong>. The test statistic is calculated as: \[t = \frac{(\bar{Y_1} - \bar{Y_2}) - (\mu_1 - \mu_2)_0}{SE_{Y_1 - Y_2}}\]
      </p>
      <p>
        This test assumes three major things:
      </p>
      <p>
        <ol>
          <li style="color:blueviolet; font-size:calc(12px + 0.7vw);">1) Normality </li>
          <li style="color:blueviolet; font-size:calc(12px + 0.7vw);">2) Homoskedasticity </li>
          <li style="color:blueviolet; font-size:calc(12px + 0.7vw);">3) Independence</li>
        </ol>
      </p>
      <p>
        Our question is as it stands is simply that we believe there is a size difference between crabs from different locations. Let's start by attempting to justify these assumptions, and if we can, using the simple test. 
      </p>
      </section>
      <section id="ttest">
        <h2>Two-sided T-tests</h2>
        <p>
          We'll use data on crab sizes: 
        </p>
        <p>
          Now what? Well there are other tests available to us!! A reminder that parametric tests like the t-test, often have a non-parametric alternative, that usually relax assumptions of normality, and are good for data with small sample sizes. Here we have only 28 observations in each group, and non-normality so let's turn to the non-parametric tests. 
        </p>
        <!--begin.rcode
        library(lterdatasampler)
        crab_sizes <- lterdatasampler::pie_crab
        end.rcode-->
        <p>
          There are a number of sites in this dataset, so let's compare crabs from two northern sites and two southern sites. Our northern sites will be "Cape Cod" and "Narragansett Bay NERR" and our southern sites will be "Guana Tolomoto Matanzas NERR" and "Sapelo Island NERR". 
        </p>
        <p>
          It's important to never forget the underlying mathematics of what we're doing, we should never simply rely on our computers exclusively and not understand what we're doing, so let's review the equations underlying the t-test. We'll be calculating the test statistic \(t\) as described above. As we are testing a hypothesis that the sizes <em>are</em> different, we can state this formally as \(H_0: \mu_1 = \mu_2\) and \(H_1: \mu_1 \neq \mu_2\). 
        </p>
        <p>
          Since we stated we believe \(H_0: \mu_1 = \mu_2\), this is a two-sided test, we have not suggested that \(\mu_1 > \mu_2\) or \(\mu_1 < \mu_2\).
        </p>
        <section id="ttest--ass">
          <h3>Assumptions of the Test</h3>
          <p>
            Before we proceed we need to take into account assumptions of our chosen test. We'll assume our samples are independent, but our two-sample t-test requires two other things: 1) normality, and 2) homoskedasticity. 
          </p>
          <section id="ttest--ass--norm">
            <h4>Normality</h4>
            <p>
              To assess the normality of our data, let's first assess it visually and then double-check with a statistical test of normality (the Shapiro-Wilks test). A convenient package for this task is the <code>ggpubr</code> package which allows to to plot density plots and QQ plots. 
            </p>
            <p>
              Let's use a density plot to check if the data follow the normal/Gaussian curve:
            </p>
            <!--begin.rcode, warning=FALSE
            library(ggpubr)
            library(dplyr)

            # first, cut our data to just the sites we want
            crab_sizes_south <- crab_sizes %>% 
              dplyr::filter(site %in% c("GTM", "SI")) 
            crab_sizes_north <- crab_sizes %>% 
              dplyr::filter(site %in% c("CC", "NB"))

            # plot our variable of interest (size)
            ggpubr::ggdensity(crab_sizes_north$size, main = "Northern")
            ggpubr::ggdensity(crab_sizes_south$size, main = "Southern")

            end.rcode-->
            <p>
              They both look normal. Let's look at the QQ plots:
            </p>
            <!--begin.rcode
            ggpubr::ggqqplot(crab_sizes_north$size, main = "North")
            ggpubr::ggqqplot(crab_sizes_south$size, main = "South")
            end.rcode-->
            <p>
              We're looking for the points to follow the black line and for no points to be outside the grey error bars. Both of these look pretty good. Let's use a Shapiro-Wilk's test to take a look at what we see. <strong>Importantly, a Shapiro-Wilk's test is a significance test that has a null hypothesis of normality. If the test is SIGNIFICANT then there is sufficient non-normality to stop our test and re-evaluate</strong>. 
            </p>
            <p>
              We can do this in R very easily. The function <code>shapiro.test()</code> comes shipped in core R with the <code>stats</code> package. First for the northern sites: 
            </p>
            <!--begin.rcode
            stats::shapiro.test(crab_sizes_north$size)
            end.rcode-->
            <p>
              Okay, and we see that our p-value is > 0.05 so we'll fail to reject the null. For the southern sites: 
            </p>
            <!--begin.rcode
            stats::shapiro.test(crab_sizes_south$size)
            end.rcode-->
            <p>
              Here we see a large p-value, >> 0.05, so again we'll reject the null. 
            </p>
            <p>
              <strong> Good, we've satisfied the condition of normality </strong>.
            </p>
          </section>
          <section id="ttest--ass--homo">
            <h4>Homoskedasticity</h4>
            <p>
              Our second assumption was that the variances of the two samples be equal. If they are not (heteroskedasticity), all is not lost and we can use a different version of the t-test. <strong>We will test our homoskedasticity with the F-test </strong>. Again, similar to the normality test, the null hypothesis of the F-test is that the variances <em> are </em> equal, so if p &lt; 0.05 then for our purposes we could say that the assumption of homoskedasticity is violated. 
            </p>
            <p>
              To do the F-test let's use the <code>stats</code> package function <code>var.test()</code>. We will just pass the two sets of data as arguments. 
            </p>
            <!--begin.rcode
            stats::var.test(crab_sizes_north$size, crab_sizes_south$size)
            end.rcode-->
            <p>
              Great, p >> 0.05, so we can continue. 
            </p>
          </section>
        </section>
        <section id="ttest--test">
          <h3>The test</h3>
          <p>
            So now we can actually perform the test. It's quite simple, we'll use the <code>t.test()</code> function: 
          </p>
          <!--begin.rcode
          t_test_res <- stats::t.test(
            # sample of group 1
            crab_sizes_north$size, 
            # sample of group 2
            crab_sizes_south$size,
            # Regulat t-test or Welch's t-test depending on the variance
            var.equal = TRUE
          )
          t_test_res
          end.rcode-->
          <p>
            We see our result here, and it turns out the p-value is <em>very</em> small, so we can reject the null hypothesis, there is good evidence that $\mu_1 \neq \mu_2$. <strong>NOTE</strong> that if our data were heteroskedastic, then we could specify <code>var.equal = FALSE</code> and that would perform a Welch's t-test which allows for this. 
          </p>
          <p>
            If we wanted, we could plot this result as a box plot, or perhaps more usefully, a violin plot (For a full walk through of how to iteratively make this plot, see our section on plotting <a href="../03-plot/03-10-values-between-groups.html">Values Between Groups</a>): 
          </p>
          <!--begin.rcode
          library(ggplot2)
          library(ggthemes)

          # first get one dataframe with the four sites we want
          focal_sites <- crab_sizes %>% 
            dplyr::filter(site %in% c("CC", "NB", "GTM", "SI")) %>% 
            # make new column to denote our two groupings
            dplyr::mutate(
              group = as.factor(ifelse(
                # if the site is CC or NB, the value of `group` is "north" if not, "south"
                site %in% c("CC", "NB"), "North", "South"
              ))
            ) %>% 
            # keep only the columns we need
            dplyr::select(size, group)

          # plot the data 
          ggplot(data = focal_sites) + 
            geom_violin(aes(x = group, y = size, fill = group)) + 
            stat_summary(aes(x = group, y = size), 
                        fun = "mean", 
                        geom = "crossbar", 
                        width = 0.5,
                        colour = "black") +
            ggthemes::theme_base() + 
            labs(y = "Size (mm)", x = "Geographic Region") + 
            theme(
              legend.position = "none"
            ) + 
            annotate(
              geom = "text", 
              x = 2.1,
              y = 21,
              label = "p < 0.001",
              size = 8
            )
          end.rcode-->
        </section>
      </section>
      <section id="oneside">
        <h2>One-sided T-tests</h2>
        <p>
          In our above example we stated our hypothesis such that we could use a two-sided test. But what if when we were formulating our hypotheses, we'd said we believe the southern crabs would be bigger? <strong>Note that we're pretending here that we HAVEN'T seen the results just above, since that would be p-hacking</strong>. But let's say we thought "Hey, warmer water, lots of sun, maybe more beaches, that could mean bigger crabs." (I stress this is not an intelligently derrived biological hypothesis).
        </p>
        <p>
          But in this case, we could perform the exact test as above, but instead determine that we wanted a one-sided test. That's easy enough and uses all the same code, with one additional argument. Using the same dataset, we would simply add an argument for <code>alternative</code>. The syntax here is saying that in the function, we pass two sets of numbers, <code>x</code> and <code>y</code>. If we believe x to be <em>less</em> than y, we pass "less", and if we believe x to be <em>greater</em> than y, then we pass "greater". 
        </p>
        <p>
          In our case, we are hypothesizing that the southern crabs (<code>crab_sizes_south</code>) are greater in size than the northern crabs, so let's set <code>x</code> to be the <code>crab_sizes_south</code> and the y to be <code>crab_sizes_north</code>, and then <code>alternative = "greater"</code>, so this is testing the alternate hypothesis that \(\mu_{south} > \mu_{north}\):
        </p>
        <!--begin.rcode
        t_test_oneside_res <- stats::t.test(
          crab_sizes_south$size, 
          crab_sizes_north$size,
          var.equal = TRUE,
          alternative = "greater"
        )
        t_test_oneside_res
        end.rcode-->
        <p>
          So we see here we have a p-value of 1. Given that we <em>do</em> know which group is <em>actually</em> bigger this comes as no surprise. Although this is a good reminder: <strong>Just because our one-sided test with an $H_A: \mu_{south} > \mu_{north}$ resulted in us failing to reject the null, this does NOT mean that we can assume that in fact \(\mu_{south} > \mu_{north}\) because the null hypothesis of these tests is stated that \(H_0: \mu_{south} = \mu_{north}\)</strong>
          . 
        </p>
      </section>
      <section id="nonnormal">
        <h2>What to do with non-normality?</h2>
        <p>
          Going back to our assumptions, let's re-start our process of this test but with a different grouping of data. 
        </p>
        <p>
          What if we just took the MOST northern and southern sites alone, not groups of sites, and did a t-test on those two? say that instead of the two sites acting as our "northern" sites, we chose to use the single most northern site: "Plum Island Estuary - West Creek" (PIE), and for our southern site, we took the most southern one - "Guana Tolomoto Matanzas NERR" (GTM). If we start again by checking our assumptions, we would first have to check for normality of both our groups. 
        </p>
        <p>
          Let's start by again dividing our data:
        </p>
        <!--begin.rcode
        # southern ones stay the same
        crab_sizes_s_GTM <- crab_sizes %>% 
          dplyr::filter(site == "GTM") 

        # new sites here
        crab_sizes_n_PIE <- crab_sizes %>% 
          dplyr::filter(site == "PIE")

        # plot our variable of interest (size)
        ggpubr::ggdensity(crab_sizes_s_GTM$size, main = "GTM")
        ggpubr::ggdensity(crab_sizes_n_PIE$size, main = "PIE")
        end.rcode-->
      <p>
        Okay, so these data look somewhat skewed. Let's do our Shapiro-Wilk's test: 
      </p>
      <!--begin.rcode
      stats::shapiro.test(crab_sizes_s_GTM$size)
      end.rcode-->

      <!--begin.rcode
      stats::shapiro.test(crab_sizes_n_PIE$size)
      end.rcode-->
      <p>
        Okay, so our p-values for both are &lt; 0.05, so we have to reject the null - these data are non-normal. 
      </p>
      <p>
        Now what? Well there are other tests available to us!! A reminder that parametric tests like the t-test, often have a non-parametric alternative, that usually relax assumptions of normality, and are good for data with small sample sizes. Here we have only 28 observations in each group, and non-normality so let's turn to the non-parametric tests. 
      </p>
    </section>
    <section id="nonpara">
      <h2>Non-Parametric Tests</h2>
      <p>The best alternative for our case is the <strong> Mann-Whitney U Test</strong>.</p>
      <p>
        There are a few things to note about this test however. <strong> This test actually does NOT compare sample means</strong>. The Mann-Whitney's stated use is to determine whether or not the groups or samples are drawn from equal populations, that is, are the shape of the data the same. It can be interpreted that this is analogous to saying the median values are the same for both groups. 
      </p>
      <section id="nonpara--ass">
        <h3>Assumptions</h3>
        <p>
          Just because the data do not have to be normal, there are still important assumptions we need to satisfy. The data still need to be independent, but there are two additional assumptions:
        </p>
        <p>
          <ol>
            <li style="color:blueviolet; font-size:calc(12px + 0.7vw);">1) The variable needs to be continuous </li>
            <li style="color:blueviolet; font-size:calc(12px + 0.7vw);">2) The data are assumed to be similar in shape </li>
          </ol>
        </p>
        <p>
          The second assumption here is important! While the data do not have to be normal, they have to exhibit a similar skew. 
        </p>
        <section id="nonpara--ass--cont">
          <h4>Continuity</h4>
          <p>
            We know that our variable is continuous, so this assumption is met. 
          </p>
        </section>
        <section id="nonpara--ass--skew">
          <h4>Skew</h4>
          <p>
            Measuring a degree of skew is somewhat arbitrary and can be difficult. It is beyond the scope of this tutorial to do so, and so we will satisfy ourselves with simply stating that the density distributions are both left-skewed, and leave it at that. 
          </p>
        </section>
      </section>
      <section id="nonpara--test">
        <h3>The test</h3>
        <p>
          The Mann-Whitney is sometimes referred to as the Mann-Whitney-Wilcoxon test, and so is performed using the <code>wilcox.test()</code> function, again from <code>stats</code>:
        </p>
        <!--begin.rcode
        stats::wilcox.test(crab_sizes_s_GTM$size,
                          crab_sizes_n_PIE$size)
        end.rcode-->
        <p>
          Here we see our p-value is &lt;&lt; 0.05, so we can reject our null hypothesis that say that these two medians are equal, and thus conclude (generally) that the northern and southern populations have different sizes. Note again that this is a two-sided test so we're not testing directionality. 
        </p>
      </section>
    </section>
    
<!-- End page content -->
<hr>
<p style="font-size:10px;color:gray;text-align:center">
    <br>
    <br>
    The EEB R Manual is the work of researchers at the University of the Toronto
     and intended as a purely educational resource. It holds no official 
    association with the R Foundation. It should not be taken as an
     authority on R best practices. 
    <br>
    When using this resource, <bold>always</bold> default to instructions and 
    guidance provided by your instructor. 
    <br>
    This content is reviewed regularly for errors and to make improvements, if you see an error and want to help us make this better, see the Contact Page
</p>
</div>
</main>
</body>
</html>
 